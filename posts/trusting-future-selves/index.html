<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Trusting Our Future Selves | Lambda Continuum</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <h1>Lambda Continuum</h1>
        <link rel="canonical" type="text/html" href="https://lambdacontinuum.github.io/" title="Lambda Continuum" />
        <link rel="alternate" type="application/rss+xml" href="https://lambdacontinuum.github.io/index.xml" title="Lambda Continuum" />

  </head>

<hr/>

<div class="article-meta">
<h1><span class="title">Trusting Our Future Selves</span></h1>

<h2 class="date">2025/04/06</h2>
</div>

<main>
<p>Is it rational to believe what you would believe in the future? Consider the principle of reflection, where if one is rational then, letting Ct1 be their credence at time t1 and Ct2 be their credence at time t2, Ct1(H|Ct2(H) = x) = x.</p>
<p>This is to say that if an agent is rational, then given that they know their later credence in some hypothesis H is x, the agent&rsquo;s earlier credence in H should be x. One may understand this principle as expressing one&rsquo;s trust in one&rsquo;s future self such that they should defer to them.</p>
<p>This may seem obvious to some, but it faces two types of counter-examples. The first is memory loss. Suppose t1 is 4/5/2025. Looking outside, I see the weather is rainy, and so my credence that the weather on 4/5/2025, is rainy is, let&rsquo;s say, 0.999. I&rsquo;ll suppose t2 is 4/5/2030, 5 years from now. If I was asked how likely it is the weather was rainy on 4/5/2025, I wouldn&rsquo;t recall that it was rainy; maybe my credence would be around, I don&rsquo;t know, 0.35? If I endorsed reflection, I should defer to my future self though, that is, Ct1(H|Ct2(H) = 0.35) = 0.35 but this seems clearly wrong. I should ignore my future forgetful state and hold Ct1(H|Ct2(H) = 0.35) = 0.999, so reflection cannot be a constraint on rationality. As long as one expects to forget in the future, they should violate reflection.</p>
<p>David Christensen offers a hypothetical involving a drug called LSQ that, upon taking it, causes one to believe that they can fly by flapping their arms. So, after taking the drug at t2, Ct2(H) = 1, but knowing prior to taking the drug that you&rsquo;ll be taking it at t1, you obviously shouldn&rsquo;t believe you can fly, so Ct1(H|Ct2(H) = 1) = 0.001, which violates reflection. If one expects to be irrational in the future, they should violate reflection.</p>
<p>So we have two instances of failure for reflection, but there does still feel something appealing about deferring to a version of ourselves with more experience, so maybe we should qualify reflection. Say in cases where we are sure we won&rsquo;t forget anything and we are sure our belief change will be rational, i.e., all our belief change will be the result of conditionalization, we should satisfy reflection.</p>
<p>Now it turns out that the qualification against memory loss is redundant as an agent whose beliefs are always the result of conditionalization won&rsquo;t experience memory loss, so we can characterize our qualified reflection as saying agents should satisfy reflection if and only if they are certain they&rsquo;ll always be conditionalizers.</p>
<p>The problem is clear: we aren&rsquo;t always conditionalizers. Quite the opposite, we&rsquo;re flawed agents susceptible to forgetting and irrationality, and so we ought not abide by reflection. Ideally rational agents, on the other hand, ought to satisfy reflection. The upshot of all this is the constraints ideal agents ought to satisfy come apart from the constraints actual people in the epistemic landscape should satisfy. There are ways in which we ought not emulate ideal epistemic agents.</p>

</main>

  <footer>
  <hr/>
  <a href="/"> home</a> | <a href="/other">other</a> | <a href="/posts">posts</a> | <a rel="rss" href="/index.xml">rss</a>


  
  </footer>
  </body>
</html>

